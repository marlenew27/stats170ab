{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Modeling Attempt\n",
    "\n",
    "### However, due to the extremely large account data size, the fitting and predicting process even could not execute within a reasonable time range (>8hrs). Therefore, we only kept the script here as an attempt record but didn't consider any output from this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1622494238402,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "4uYw16oOECSn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, roc_curve,r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhZsrM5uGdvo"
   },
   "outputs": [],
   "source": [
    "# !pip install boto3==1.13.11\n",
    "# !pip install s3fs==0.4.2\n",
    "# !pip install botocore==1.20.74\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import colors\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import scale\n",
    "# import seaborn as sns\n",
    "\n",
    "# import boto3\n",
    "# from botocore.client import Config\n",
    "# import s3fs \n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RidV7W90ECSs"
   },
   "source": [
    "# Choose the Organization of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1622494266487,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "CH1LsS9yECSt"
   },
   "outputs": [],
   "source": [
    "# org = \"USC\"\n",
    "# org = \"TAM\"\n",
    "org = \"OKLAHOMA\"\n",
    "# org = \"BAYLOR\"\n",
    "# org = \"ECU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKTWcmcNECSu"
   },
   "source": [
    "# Load Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1622494270481,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "ZcEER6YEFSid",
    "outputId": "57b19dcb-4b49-45ef-e360-1119cab0ada4"
   },
   "outputs": [],
   "source": [
    "# mount the drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3180,
     "status": "ok",
     "timestamp": 1622492806447,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "o9quBiVuECSu"
   },
   "outputs": [],
   "source": [
    "# Load Account Data For a Specific Organization\n",
    "account = pd.read_csv(\"/Users/yihan/Downloads/acc_tags_set.csv\")\n",
    "account = account[account.org_id==org].copy()\n",
    "account.drop(columns = [\"nan_tag\"], inplace = True)\n",
    "\n",
    "interested_tags = set()\n",
    "acc_tag_dict = defaultdict(int)\n",
    "for i in range(len(account)):\n",
    "    tag_list = ast.literal_eval(account.tags.iloc[i])\n",
    "    for t in tag_list:\n",
    "        acc_tag_dict[t]+=1\n",
    "        interested_tags.add(t)\n",
    "account_per_tag = []\n",
    "for k,v in acc_tag_dict.items():\n",
    "    account_per_tag.append({\"tag\":k,\"counts\":v })\n",
    "account_per_tag = pd.DataFrame(account_per_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS2yOtdkECSv"
   },
   "source": [
    "# Load Seasonal Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1622492814967,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "oDlfQUCVG1HZ"
   },
   "outputs": [],
   "source": [
    "# mykey = \"AKIAZASEX6JHG2B6IG74\"\n",
    "# mysecretkey = \"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\"\n",
    "\n",
    "# config = Config(connect_timeout=120, \n",
    "#                 retries={'max_attempts': 10})\n",
    "# s3 = boto3.resource(\n",
    "#     service_name='s3',\n",
    "#     region_name='us-west-2',\n",
    "#     aws_access_key_id=mykey,\n",
    "#     aws_secret_access_key=mysecretkey\n",
    "# )\n",
    "# client = boto3.client(\n",
    "#     service_name='s3',\n",
    "#     region_name='us-west-2',\n",
    "#     aws_access_key_id=mykey,\n",
    "#     aws_secret_access_key=mysecretkey,\n",
    "#     config=config\n",
    "# )\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = 'us-west-2'\n",
    "# os.environ[\"AWS_ACCESS_KEY_ID\"] = mykey\n",
    "# os.environ[\"AWS_SECRET_ACCESS_KEY\"] = mysecretkey\n",
    "\n",
    "# bucket = 'uci-capstone-custfields'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "executionInfo": {
     "elapsed": 3076,
     "status": "error",
     "timestamp": 1622494324907,
     "user": {
      "displayName": "Yihan Wang",
      "photoUrl": "",
      "userId": "06041494629110133871"
     },
     "user_tz": 420
    },
    "id": "wCx6zpHUG80E",
    "outputId": "83821a66-084a-4c92-847a-e2f0afa2c1a0"
   },
   "outputs": [],
   "source": [
    "#ticket_sea = pd.read_csv(\"s3://uci-capstone-custfields/raw/ticket_trans_item_event.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4ncm9jiECSv"
   },
   "outputs": [],
   "source": [
    "#ticket_season = ticket_sea[ticket_sea.org_id.isin([org])].copy()\n",
    "ticket_season = pd.read_csv('/Users/yihan/Desktop/oklahoma_ticket_trans_item_event.csv')\n",
    "ticket_orgs = ticket_season.org_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW5ja0_4ECSw"
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5BIQTW-ECSx"
   },
   "source": [
    "## Only select the tags that have been assigned to more than 100 accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVXysRBpECSx"
   },
   "outputs": [],
   "source": [
    "useful_tags = []\n",
    "error_tags = []\n",
    "# method = \"logit\"\n",
    "\n",
    "for i,tag in enumerate(interested_tags):\n",
    "    if type(tag)==str and account_per_tag[account_per_tag.tag==tag].iloc[0][\"counts\"] >100:\n",
    "        useful_tags.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku6Ja0NwECSy"
   },
   "source": [
    "## Pivot Wide Table so that each column is a season of the organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC8TOc4_ECSy"
   },
   "outputs": [],
   "source": [
    "ticket_season_org = ticket_season[[\"account_id\",\"org_id\",\"season\",\"total_epay\",\n",
    "                                   \"e_oqty\"]].groupby([\"account_id\",\"org_id\",\n",
    "                                                       \"season\"]).sum().reset_index()\n",
    "ticket_season_org = ticket_season_org.pivot_table(index = [\"account_id\",\"org_id\"], \n",
    "                           columns = [\"season\"],\n",
    "                           values = [\"total_epay\",\"e_oqty\"]).fillna(0)\n",
    "ticket_season_org.columns = [\"_\".join(x) if x[0] not in [\"account_id\",\"org_id\"] else x[0] for x in ticket_season_org.columns.ravel()]\n",
    "temp = pd.merge(account,ticket_season_org, on = [\"account_id\",\"org_id\"], how = \"inner\")\n",
    "temp.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_season_org = ticket_season_org.reset_index()\n",
    "ticket_season_org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z65cCcepECSz"
   },
   "source": [
    "# SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(testy, pred_y, org , tag, cross_val_num):\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = roc_auc_score(testy, pred_y)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('SVM: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, pred_y)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Tag')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='SVM')\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # save image\n",
    "    plt.savefig(f'/Users/yihan/Desktop/{org}_{tag}_cv{cross_val_num}.png',bbox_inches='tight')\n",
    "    # show the plot\n",
    "    \n",
    "    plt.show()\n",
    "    return lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NH8f5VNgECSz"
   },
   "outputs": [],
   "source": [
    "def calculate_season_svm(tag,org):\n",
    "    '''Get 5-fold Cross Validation Result for Logistic Regression in predicting whether the accounts\n",
    "    in a selected organization are assigned a selected tag.\n",
    "    Get the account and ticket data from previous codes to avoid copying too many data and crashing the session\n",
    "    '''\n",
    "    print(\"Selected Tag:\", tag)\n",
    "#     ----------------------------------Preprocess Data ----------------------------------\n",
    "#     Ticket Season: Number of Columns\n",
    "    print(\"old columns number:\",len(ticket_season_org.columns))\n",
    "    \n",
    "#     Account Data: Create Target Column to indicate whether and again return 0 if \n",
    "    tag_account = account.copy()\n",
    "    tag_account[\"tag\"] = tag_account.tags.str.contains(tag).fillna(False)\n",
    "    tag_num = len(tag_account[tag_account.tag])\n",
    "    if tag_num<100:\n",
    "        return 0\n",
    "    \n",
    "#     Merge Account + Ticket Season    \n",
    "    temp = pd.merge(tag_account,ticket_season_org, on = [\"account_id\",\"org_id\"], how = \"left\")\n",
    "    total_number_of_account = len(temp)\n",
    "    total_number_of_acc_w_tag = len(temp[temp.tag])\n",
    "    print(\"total number of accounts labeled with tag: \", total_number_of_acc_w_tag)\n",
    "    print(\"total number of accounts: \",total_number_of_account)\n",
    "    print(\"percentage of tags: \",total_number_of_acc_w_tag/total_number_of_account)\n",
    "    \n",
    "    if len(temp[temp.tag])<100:     \n",
    "        return 0\n",
    "    \n",
    "    temp.fillna(0,inplace = True)   \n",
    "    \n",
    "#     Drop Season Columns if fewer than 1000 accounts have bought relevant tickets:\n",
    "    temp[\"intercept\"] = 1\n",
    "    temp.drop(columns = [\"tags\"], inplace = True)\n",
    "    drop_cols = []\n",
    "    for c in temp.columns:\n",
    "        if c not in [\"account_id\",\"org_id\",'tag']:\n",
    "            if len(temp[temp[c]>0])<1000:\n",
    "                drop_cols.append(c)\n",
    "    print(drop_cols)\n",
    "    temp.drop(columns = drop_cols, inplace = True)\n",
    "    \n",
    "#     The X variable Columns\n",
    "    xs = [c for c in temp.columns if c not in [\"account_id\",\"org_id\",'tag']]\n",
    "    print(\"new columns number: \",len(xs))\n",
    "\n",
    "#     Randomize the dataframe with sample and fraction = 1 and replace = False\n",
    "    np.random.seed(0)\n",
    "    temp = temp.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     -----------------------------------------------------------------------------------------\n",
    "# --------- Run SVM CLASSIFICATION on all data to get the table for p-value and coefficient---------\n",
    "#         Need to use bfgs else errors will be very frequent\n",
    "#     clf = svm.SVC(kernel='linear').fit(temp[xs],temp.tag)\n",
    "#     cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "#     scores = cross_val_score(clf, temp[xs], temp.tag, cv=cv)\n",
    "#     print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    \n",
    "#    -------------------------------------------------------------------------------------------    \n",
    "#     ------------------5-FOLD Cross Validation Data Preprocess-------------------\n",
    "\n",
    "#     Split the data with tag from no tag for future 5-fold splitting\n",
    "    temp_tag = temp[temp.tag].copy()\n",
    "    temp = temp[~temp.tag]\n",
    "\n",
    "#     # Tags Train Split - index\n",
    "    arr_tags = np.arange(len(temp_tag))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(arr_tags)\n",
    "    arr_tags=np.array_split(arr_tags, 5)\n",
    "    \n",
    "#     # Not Tags Train Split - index\n",
    "    arr_no_tags = np.arange(len(temp))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(arr_no_tags)\n",
    "    arr_no_tags=np.array_split(arr_no_tags, 5)\n",
    "    \n",
    "    temp.reset_index(inplace = True)\n",
    "    temp_tag.reset_index(inplace = True)\n",
    "\n",
    "#     ------------------5-FOLD Cross Validation and Metrics-------------------\n",
    "    \n",
    "    average_mse =0\n",
    "    avg_specificity = 0\n",
    "    avg_sensitivity = 0\n",
    "    avg_f1 = 0\n",
    "    sense_gd=True\n",
    "    spec_gd = True\n",
    "    avg_auc_score=0\n",
    "    for i,(ari1, ari2) in enumerate(zip(arr_no_tags, arr_tags)):\n",
    "#         Train Test split using the previously prepared indexes in each fold\n",
    "        temp_test = pd.concat([temp.iloc[ari1],\n",
    "                             temp_tag.iloc[ari2]]).reset_index()\n",
    "        temp_tr = pd.concat([temp.drop(ari1,axis =0),\n",
    "                               temp_tag.drop(ari2,axis =0)])\n",
    "        temp_tr = temp_tr.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#       Train SVM Model \n",
    "        result=svm.SVC(kernel='linear').fit(temp_tr[xs],temp_tr.tag)\n",
    "\n",
    "\n",
    "        predicted = result.predict(temp_test[xs])\n",
    "    \n",
    "#       Calculate AUC Score and Plot ROC Curve\n",
    "        auc_score = plot_roc(temp_test.tag,predicted,org,tag,i)\n",
    "        avg_auc_score+=auc_score\n",
    "        \n",
    "#       Use 0.5 as threshold: <0.5 means no tag; >=0.5 means tag\n",
    "        predicted = np.where(predicted<0.5,0,1)\n",
    "        \n",
    "#         Calculate Measure Metrics:\n",
    "#       mse, true_positive, false_negative,true_negative,false_positive\n",
    "        mse = np.sum((predicted - temp_test.tag)**2)/len( temp_test.tag)\n",
    "\n",
    "        average_mse+=mse\n",
    "        true_positive = 0\n",
    "        false_negative = 0\n",
    "        true_negative = 0\n",
    "        false_positive= 0\n",
    "        \n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] and temp_test.tag.iloc[i]:\n",
    "                true_positive+=1\n",
    "            elif not predicted[i] and not temp_test.tag.iloc[i]:\n",
    "                true_negative+=1\n",
    "            elif predicted[i] and not temp_test.tag.iloc[i]:\n",
    "                false_negative+=1\n",
    "            else:\n",
    "                false_positive+=1\n",
    "        print(true_positive,false_negative,true_negative,false_positive)\n",
    "        if true_positive+false_negative!=0:\n",
    "            sensitivity = true_positive/(true_positive+false_negative)\n",
    "            avg_sensitivity+=sensitivity\n",
    "#             print(i,\"sensitivity:\",sensitivity)\n",
    "        else:\n",
    "            sense_gd=False\n",
    "        if true_negative+false_positive!=0:\n",
    "            specificity = true_negative/(true_negative+false_positive) \n",
    "            avg_specificity+=specificity\n",
    "#             print(i,\"specificity:\",specificity)\n",
    "        else:\n",
    "            spec_gd = False\n",
    "            \n",
    "        avg_f1 += true_positive/(true_positive+(false_positive+false_negative)/2)\n",
    "\n",
    "        \n",
    "    if sense_gd:\n",
    "        avg_sensitivity = avg_sensitivity/5\n",
    "        print(\"avg_sensitivity: \",avg_sensitivity)\n",
    "    if spec_gd:\n",
    "        avg_specificity = avg_specificity/5\n",
    "        print(\"avg_specificity: \",avg_specificity)\n",
    "        \n",
    "    avg_f1 = avg_f1/5\n",
    "    print(\"avg_f1 score: \", avg_f1)\n",
    "              \n",
    "    average_mse = average_mse/5\n",
    "    print(\"average_mse score: \", average_mse)\n",
    "    \n",
    "    avg_auc_score = avg_auc_score/5\n",
    "    print(\"avg_auc_score score: \", avg_auc_score)\n",
    "    \n",
    "    r2 = r2_score(temp_test.tag,predicted)\n",
    "    \n",
    "    result = {\"prsquared\": r2, \n",
    "              \"total_number_of_account\":total_number_of_account,\n",
    "              \"total_number_of_acc_w_tag\":total_number_of_acc_w_tag,\n",
    "              \"Percentage of Tag\": total_number_of_acc_w_tag/total_number_of_account,\n",
    "              \"Correct Percentage\":average_mse,\n",
    "              \"avg_f1\":avg_f1,\n",
    "              \"avg_auc\": avg_auc_score,\n",
    "              \"avg_sensitivity\":avg_sensitivity,\n",
    "              \"avg_specificity\":avg_specificity,\n",
    "              \"sense_gd\":sense_gd, \n",
    "              \"spec_gd\":spec_gd}\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCeD78LZECS2"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMjzKL1SECS2"
   },
   "outputs": [],
   "source": [
    "# Tried only run one organization's account data but still failed\n",
    "tags_dict = dict()\n",
    "for tag in useful_tags:\n",
    "    print(tag)\n",
    "    result = calculate_season_svm(tag,\"OKLAHOMA\")\n",
    "    print(result)\n",
    "    if result!=0:\n",
    "        tags_dict[tag] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QfvcQx9ECS2"
   },
   "source": [
    "## Format Result (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbMqhnkWECS3"
   },
   "outputs": [],
   "source": [
    "def format_model_result(tags_dict, sort_by_cols=[\"avg_sensitivity\",\"avg_specificity\"]):\n",
    "    temp = []\n",
    "    for k,v in tags_dict.items():\n",
    "        tags_dict[k][\"tag\"]=k\n",
    "        temp.append(tags_dict[k])\n",
    "    tags_dict = pd.DataFrame(temp)\n",
    "    return tags_dict.sort_values(by = sort_by_cols,ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0bKSOzjECS4"
   },
   "source": [
    "## Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P8WgLDvECS4"
   },
   "outputs": [],
   "source": [
    "format_model_result(tags_dict, [\"avg_sensitivity\",\"avg_specificity\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "7. Reason of Tagging (SVM Version).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
