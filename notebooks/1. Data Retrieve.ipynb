{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import snowflake.connector as sfc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import time\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "from io import StringIO\n",
    "from smart_open import smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omni = sfc.connect(\n",
    "    user='cs2021_user3',\n",
    "    password='Cap2021Stone-3',\n",
    "    account='paciolan',\n",
    "    warehouse='INTERNAL_ANALYTICS_WH',#'capstone2021_wh',\n",
    "    database='omni_raw',\n",
    "    schema='FUND',\n",
    "    role = 'CAPSTONE2021_ROLE'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs = omni.cursor()\n",
    "# cur = cs.execute('''SELECT DISTINCT DATA:z_lastupdatedusertimestamp::string as z_lastupdatedusertimestamp from accounts''')\n",
    "cur = cs.execute('''SELECT DISTINCT \n",
    "                    DATA:z_lastupdatedusertimestamp::string as z_lastupdatedusertimestamp,\n",
    "                    DATA:accountname::string as account_name,\n",
    "                    DATA:id::string as account_id,\n",
    "                    DATA:dbid::string as client_id,\n",
    "                    DATA:keywords as keywords, \n",
    "                    DATA:userdefinedfields as userdefinedfields,\n",
    "                    DATA:tags as tags,\n",
    "                    DATA:preferredemail::string as preferredemail,\n",
    "                    DATA:preferredcontactmethod as preferredcontactmethod\n",
    "                    from accounts  \n",
    "                    limit 31728370\n",
    "                    offset 31728370''')\n",
    "print(\"execution_finished\")\n",
    "account_df2 = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "print(account_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "account_df2.to_csv(\"all_accounts_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "account_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Connect to S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "import s3fs \n",
    "import os\n",
    "mykey = \"here is our key, we delete it for submission\"\n",
    "mysecretkey = \"key\"\n",
    "config = Config(connect_timeout=120, \n",
    "                retries={'max_attempts': 10})\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    region_name='us-west-2',\n",
    "    aws_access_key_id=mykey,\n",
    "    aws_secret_access_key=mysecretkey\n",
    ")\n",
    "client = boto3.client(\n",
    "    service_name='s3',\n",
    "    region_name='us-west-2',\n",
    "    aws_access_key_id=mykey,\n",
    "    aws_secret_access_key=mysecretkey,\n",
    "    config=config\n",
    ")\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = 'us-west-2'\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = mykey\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = mysecretkey\n",
    "\n",
    "bucket = 'uci-capstone-custfields'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Upload file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# s32 = boto3.resource('s3')\n",
    "s3 = boto3.client('s3')\n",
    "with open('all_accounts.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/all_accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# s32 = boto3.resource('s3')\n",
    "s3 = boto3.client('s3')\n",
    "with open('all_accounts_2.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/all_accounts_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clean Data First Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def convert_datetime(timestamp):\n",
    "    if type(timestamp) == float and np.isnan(timestamp):\n",
    "        return pd.to_datetime(timestamp)\n",
    "    elif type(timestamp) == str and \"T\" in timestamp:\n",
    "        return str(pd.to_datetime(timestamp)).replace(\"+00:00\", \"\").split(\".\")[0]\n",
    "    elif type(timestamp) == str and len(timestamp) == 0:\n",
    "        return pd.to_datetime(np.nan)\n",
    "    else:\n",
    "        timestamp = int(timestamp)\n",
    "        if np.isnan(timestamp):\n",
    "            return pd.to_datetime(timestamp)\n",
    "        return str(datetime.fromtimestamp(timestamp/1000.0)).split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def to_dict(x):\n",
    "    result = dict()\n",
    "    if type(x) == str and x != \"\":\n",
    "        x = ast.literal_eval(\"[\"+x+\"]\")\n",
    "        for d in x:\n",
    "            result[d[\"value1\"]] = d[\"value2\"]\n",
    "        return str(result)[1:-1]\n",
    "    return np.nan\n",
    "            \n",
    "def to_nan(x):\n",
    "    if type(x) == str and x ==\"\":\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def only_comma(x):\n",
    "    return len(x.replace(\",\",\"\"))==0\n",
    "def remove_duplicates(x):\n",
    "    if type(x) == str and x != \"\" and not only_comma(x):\n",
    "        x = \"{\"+x+\"}\"\n",
    "        x = ast.literal_eval(x)\n",
    "        return str(x)\n",
    "    return np.nan\n",
    "\n",
    "def remove_duplicates2(x):\n",
    "    if type(x) == str and x != \"\" and not only_comma(x):\n",
    "        x = x.strip(\",\")\n",
    "        x= re.sub(r',+',',',x)\n",
    "        x = re.sub(\"[\\{\\}]\",\"\",x)\n",
    "        x = \"{\"+x+\"}\"\n",
    "        x = ast.literal_eval(x)\n",
    "        return str(x)\n",
    "    return np.nan       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "testing_orgid = [\"SPORTS\",\"ARTSDEMO\",\"CLASS1\",\"CLASS3A\",\"CICD80\"]\n",
    "concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    " \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "account_df2 = pd.read_csv(\"all_accounts.csv\", chunksize = 100000)\n",
    "for i,chunk in enumerate(account_df2):\n",
    "    if i >= 281:\n",
    "        print(i)\n",
    "        print(\"before removing:\",len(chunk))\n",
    "        chunk.drop(columns = [\"Unnamed: 0\"], inplace =True)\n",
    "        chunk.rename(columns = {\"CLIENT_ID\":\"org_id\",\"ACCOUNT_ID\":\"ACCOUNT_ID\".lower(),\n",
    "                               \"ACCOUNT_NAME\":\"account_name\",\"KEYWORDS\":\"KEYWORDS\".lower(),\n",
    "                               \"USERDEFINEDFIELDS\":\"USERDEFINEDFIELDS\".lower(),\n",
    "                               \"TAGS\":\"tags\",\"PREFERREDEMAIL\":\"preferredemail\",\n",
    "                               \"PREFERREDCONTACTMETHOD\":\"preferredcontactmethod\"}, \n",
    "                     inplace = True)\n",
    "        chunk[\"account_name\"] = \"\\\"\"+chunk[\"account_name\"].apply(lambda x: x.replace(\"\\\"\",\"\\'\").replace(\"\\\\\",\"\") if type(x)==str else x)+\"\\\"\"\n",
    "#         chunk[\"account_name\"] = chunk[\"account_name\"].apply(lambda x: x.replace(\"\\\\\",\"\") if type(x)==str else x)\n",
    "        chunk[\"preferredemail\"] =\"\\\"\"+chunk[\"preferredemail\"].apply(lambda x: x.replace(\"\\\"\",\"\\'\").replace(\"\\\\\",\"\") if type(x)==str else x)+\"\\\"\"\n",
    "        chunk = chunk[~chunk.org_id.isin(testing_orgid)].copy()\n",
    "        print(\"after removing testing accounts:\",len(chunk))\n",
    "\n",
    "        ### Simple Formatting\n",
    "        for col in cols:\n",
    "            chunk[col] = chunk[col].astype(str)\n",
    "            chunk[col] = chunk[col].apply(lambda x: x.replace(\"\\n \",\"\"))\n",
    "            chunk[col] = chunk[col].apply(lambda x: x.replace(\"[\",\"\"))\n",
    "            chunk[col] = chunk[col].apply(lambda x: x.replace(\"]\",\"\"))\n",
    "            chunk[col] = chunk[col].apply(lambda x: \"\" if x == \"nan\" else x)\n",
    "            chunk[col] = chunk[col].apply(lambda x: x.replace(\"\\n\",\"\"))\n",
    "        chunk[\"Z_LASTUPDATEDUSERTIMESTAMP\"] =chunk.Z_LASTUPDATEDUSERTIMESTAMP.apply(convert_datetime)\n",
    "        chunk = chunk[pd.to_datetime(chunk.Z_LASTUPDATEDUSERTIMESTAMP)>=datetime(2018,1,1)].copy()\n",
    "        chunk.sort_values(by = [\"Z_LASTUPDATEDUSERTIMESTAMP\"], inplace = True)\n",
    "        result = chunk[[\"account_id\", \"org_id\"]].copy()\n",
    "\n",
    "        ### Merge into Set or Dict (only keep the earliest records)\n",
    "        for col in concat_cols:\n",
    "            print(col)\n",
    "            if col == \"userdefinedfields\":\n",
    "                chunk[col]=chunk[col].apply(to_dict)\n",
    "            else:\n",
    "                chunk[col] = chunk[col].apply(to_nan)\n",
    "            temp = chunk[[col,\"account_id\",\n",
    "                        \"org_id\"]].dropna()\n",
    "            temp = pd.DataFrame(temp.groupby([\"account_id\",          \n",
    "                               \"org_id\"])[col].apply(','.join).apply(str.strip)).reset_index()\n",
    "            temp[col] = temp[col].apply(remove_duplicates)\n",
    "            result = pd.merge(result,temp, on =[\"account_id\", \"org_id\"], how = \"outer\")\n",
    "            result.drop_duplicates(inplace = True)\n",
    "        result.drop_duplicates(inplace = True)\n",
    "        if i == 0:\n",
    "            result.to_csv(\"s3://uci-capstone-custfields/raw/cleaned_accounts_v1.csv\",\n",
    "                          index = False)\n",
    "        else:\n",
    "            result.to_csv(\"s3://uci-capstone-custfields/raw/cleaned_accounts_v1.csv\", \n",
    "                        mode = \"a\", header = False, index = False)\n",
    "        print(len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "# testing_orgid = [\"SPORTS\",\"ARTSDEMO\",\"CLASS1\",\"CLASS3A\",\"CICD80\"]\n",
    "# concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    "#  \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "# chunk = pd.read_csv(\"all_accounts_2.csv\")\n",
    "# print(\"before removing:\",len(chunk))\n",
    "# chunk.drop(columns = [\"Unnamed: 0\"], inplace =True)\n",
    "# chunk.rename(columns = {\"CLIENT_ID\":\"org_id\",\"ACCOUNT_ID\":\"ACCOUNT_ID\".lower(),\n",
    "#                        \"ACCOUNT_NAME\":\"account_name\",\"KEYWORDS\":\"KEYWORDS\".lower(),\n",
    "#                        \"USERDEFINEDFIELDS\":\"USERDEFINEDFIELDS\".lower(),\n",
    "#                        \"TAGS\":\"tags\",\"PREFERREDEMAIL\":\"preferredemail\",\n",
    "#                        \"PREFERREDCONTACTMETHOD\":\"preferredcontactmethod\"}, \n",
    "#              inplace = True)\n",
    "# chunk[\"account_name\"] = \"\\\"\"+chunk[\"account_name\"].apply(lambda x: x.replace(\"\\\"\",\"\\'\").replace(\"\\\\\",\"\") if type(x)==str else x)+\"\\\"\"\n",
    "# #         chunk[\"account_name\"] = chunk[\"account_name\"].apply(lambda x: x.replace(\"\\\\\",\"\") if type(x)==str else x)\n",
    "# chunk[\"preferredemail\"] =\"\\\"\"+chunk[\"preferredemail\"].apply(lambda x: x.replace(\"\\\"\",\"\\'\").replace(\"\\\\\",\"\") if type(x)==str else x)+\"\\\"\"\n",
    "# chunk = chunk[~chunk.org_id.isin(testing_orgid)].copy()\n",
    "# print(\"after removing testing accounts:\",len(chunk))\n",
    "\n",
    "# ### Simple Formatting\n",
    "# for col in cols:\n",
    "#     chunk[col] = chunk[col].astype(str)\n",
    "#     chunk[col] = chunk[col].apply(lambda x: x.replace(\"\\n \",\"\"))\n",
    "#     chunk[col] = chunk[col].apply(lambda x: x.replace(\"[\",\"\"))\n",
    "#     chunk[col] = chunk[col].apply(lambda x: x.replace(\"]\",\"\"))\n",
    "#     chunk[col] = chunk[col].apply(lambda x: \"\" if x == \"nan\" else x)\n",
    "#     chunk[col] = chunk[col].apply(lambda x: x.replace(\"\\n\",\"\"))\n",
    "chunk[\"Z_LASTUPDATEDUSERTIMESTAMP\"] =chunk.Z_LASTUPDATEDUSERTIMESTAMP.apply(convert_datetime)\n",
    "chunk = chunk[pd.to_datetime(chunk.Z_LASTUPDATEDUSERTIMESTAMP)>=datetime(2018,1,1)].copy()\n",
    "chunk.sort_values(by = [\"Z_LASTUPDATEDUSERTIMESTAMP\"], inplace = True)\n",
    "result = chunk[[\"account_id\", \"org_id\"]].copy()\n",
    "\n",
    "### Merge into Set or Dict (only keep the earliest records)\n",
    "for col in concat_cols:\n",
    "    print(col)\n",
    "    if col == \"userdefinedfields\":\n",
    "        chunk[col]=chunk[col].apply(to_dict)\n",
    "    else:\n",
    "        chunk[col] = chunk[col].apply(to_nan)\n",
    "    temp = chunk[[col,\"account_id\",\n",
    "                \"org_id\"]].dropna()\n",
    "    temp = pd.DataFrame(temp.groupby([\"account_id\",          \n",
    "                       \"org_id\"])[col].apply(','.join).apply(str.strip)).reset_index()\n",
    "    temp[col] = temp[col].apply(remove_duplicates)\n",
    "    result = pd.merge(result,temp, on =[\"account_id\", \"org_id\"], how = \"outer\")\n",
    "    result.drop_duplicates(inplace = True)\n",
    "result.drop_duplicates(inplace = True)\n",
    "result.to_csv(\"s3://uci-capstone-custfields/raw/cleaned_accounts_2_v1.csv\",\n",
    "                  index = False)\n",
    "result.to_csv(\"cleaned_accounts_2_v1.csv\",\n",
    "                  index = False)\n",
    "print(len(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clean Second Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    " \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "columns = [\"account_id\",\"org_id\",\"keywords\",\"userdefinedfields\",\n",
    "           \"tags\",\"preferredemail\",\"preferredcontactmethod\",\n",
    "           \"account_name\"]\n",
    "# account_df2 = pd.read_csv(\"cleaned_accounts_v1.csv\", chunksize = 100000)\n",
    "for k in range(3,4):\n",
    "    \n",
    "    account_df2 = pd.read_csv(f\"cleaned_v1/cleaned_accounts_v1 ({k}).csv\", \n",
    "                              chunksize = 100000,\n",
    "                              names = columns)\n",
    "    for i,chunk in enumerate(account_df2):   \n",
    "        if i >= 0:\n",
    "            print(i)\n",
    "            print(\"before removing:\",len(chunk))\n",
    "            if len(chunk) != len(chunk.drop_duplicates(subset = [\"account_id\",\"org_id\"])):\n",
    "\n",
    "                ### Simple Formatting\n",
    "                for col in concat_cols:\n",
    "                    chunk[col] = chunk[col].apply(lambda x: x[1:-1] if type(x)==str and \"{\" in x else x)\n",
    "\n",
    "                ### Merge into Set or Dict (only keep the earliest records)\n",
    "                result = chunk.fillna(\"\").groupby([\"account_id\",\"org_id\"], \n",
    "                                      as_index = False).agg({\"keywords\":\",\".join,\n",
    "                                                            \"userdefinedfields\":\",\".join,\n",
    "                                                            \"tags\":\",\".join,\n",
    "                                                            \"preferredemail\":\",\".join,\n",
    "                                                            \"preferredcontactmethod\":\",\".join,\n",
    "                                                            \"account_name\":\",\".join}) \n",
    "                for col in concat_cols:\n",
    "                    result[col] = result[col].apply(remove_duplicates2)\n",
    "\n",
    "#                 if i == 0:\n",
    "                result.to_csv(f\"cleaned_v2/cleaned_accounts_v2_{k}_{i}.csv\", index = False)\n",
    "#                 else:\n",
    "#                     result.to_csv(\"cleaned_v2/cleaned_accounts_v2_{k}_{i}.csv\", \n",
    "#                                 mode = \"a\", header = False, index = False)\n",
    "                print(len(result))\n",
    "            else:\n",
    "#                 if i == 0:\n",
    "                chunk.to_csv(f\"cleaned_v2/cleaned_accounts_v2_{k}_{i}.csv\", index = False)\n",
    "#                 else:\n",
    "#                     chunk.to_csv(\"cleaned_v2/cleaned_accounts_v2_{k}_{i}.csv\", \n",
    "#                                 mode = \"a\", header = False, index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clean Third Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    " \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "columns = [\"account_id\",\"org_id\",\"keywords\",\"userdefinedfields\",\n",
    "           \"tags\",\"preferredemail\",\"preferredcontactmethod\",\n",
    "           \"account_name\"]\n",
    "# account_df2 = pd.read_csv(\"cleaned_accounts_v1.csv\", chunksize = 100000)\n",
    "######\n",
    "# chunk = pd.read_csv(\"cleaned_v2/cleaned_accounts_v2_{i}.csv\",\n",
    "#                     names = columns)\n",
    "######\n",
    "# chunk = []\n",
    "# for i in range(0,94):\n",
    "#     print(i)\n",
    "#     chunk.append(pd.read_csv(f\"cleaned_v2/cleaned_accounts_v2_1_{i}.csv\"))\n",
    "######\n",
    "# chunk = []\n",
    "# for i in range(0,72):\n",
    "#     print(i)\n",
    "#     chunk.append(pd.read_csv(f\"cleaned_v2/cleaned_accounts_v2_2_{i}.csv\"))\n",
    "######\n",
    "chunk = []\n",
    "for i in range(0,27):\n",
    "    print(i)\n",
    "    chunk.append(pd.read_csv(f\"cleaned_v2/cleaned_accounts_v2_3_{i}.csv\"))\n",
    "chunk = pd.concat(chunk)\n",
    "if len(chunk) != len(chunk.drop_duplicates(subset = [\"account_id\",\"org_id\"])):\n",
    "    print(\"len(chunk):\",len(chunk))\n",
    "    \n",
    "\n",
    "    ### Simple Formatting\n",
    "    for col in concat_cols:\n",
    "        print(\"col1:\",col)\n",
    "        chunk[col] = chunk[col].apply(lambda x: x[1:-1] if type(x)==str and \"{\" in x else x)\n",
    "\n",
    "    ### Merge into Set or Dict (only keep the earliest records)\n",
    "    result = chunk.fillna(\"\").groupby([\"account_id\",\"org_id\"], \n",
    "                          as_index = False).agg({\"keywords\":\",\".join,\n",
    "                                                \"userdefinedfields\":\",\".join,\n",
    "                                                \"tags\":\",\".join,\n",
    "                                                \"preferredemail\":\",\".join,\n",
    "                                                \"preferredcontactmethod\":\",\".join,\n",
    "                                                \"account_name\":\",\".join}) \n",
    "    for col in concat_cols:\n",
    "        print(\"col2:\",col)\n",
    "        result[col] = result[col].apply(remove_duplicates2)\n",
    "    result.to_csv(f\"cleaned_v3/cleaned_accounts_v3_3.csv\", index = False)\n",
    "\n",
    "    print(len(result))\n",
    "else:\n",
    "    chunk.to_csv(f\"cleaned_v3/cleaned_accounts_v3_3.csv\", index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Clean Fourth Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    " \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "columns = [\"account_id\",\"org_id\",\"keywords\",\"userdefinedfields\",\n",
    "           \"tags\",\"preferredemail\",\"preferredcontactmethod\",\n",
    "           \"account_name\"]\n",
    "chunk = []\n",
    "for i in range(0,4):\n",
    "    print(i)\n",
    "    chunk.append(pd.read_csv(f\"cleaned_v3/cleaned_accounts_v3_{i}.csv\"))\n",
    "chunk = pd.concat(chunk)\n",
    "if len(chunk) != len(chunk.drop_duplicates(subset = [\"account_id\",\"org_id\"])):\n",
    "    print(\"len(chunk):\",len(chunk))\n",
    "    \n",
    "    ### Simple Formatting\n",
    "    for col in concat_cols:\n",
    "        print(\"col1:\",col)\n",
    "        chunk[col] = chunk[col].apply(lambda x: x[1:-1] if type(x)==str and \"{\" in x else x)\n",
    "\n",
    "    ### Merge into Set or Dict (only keep the earliest records)\n",
    "    result = chunk.fillna(\"\").groupby([\"account_id\",\"org_id\"], \n",
    "                          as_index = False).agg({\"keywords\":\",\".join,\n",
    "                                                \"userdefinedfields\":\",\".join,\n",
    "                                                \"tags\":\",\".join,\n",
    "                                                \"preferredemail\":\",\".join,\n",
    "                                                \"preferredcontactmethod\":\",\".join,\n",
    "                                                \"account_name\":\",\".join}) \n",
    "    for col in concat_cols:\n",
    "        print(\"col2:\",col)\n",
    "        result[col] = result[col].apply(remove_duplicates2)\n",
    "    result.to_csv(f\"cleaned_v4/cleaned_accounts_v4.csv\", index = False)\n",
    "\n",
    "    print(len(result))\n",
    "else:\n",
    "    chunk.to_csv(f\"cleaned_v4/cleaned_accounts_v4.csv\", index = False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result.to_csv(f\"cleaned_v4/cleaned_accounts_v4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Upload Cleaned data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "with open('cleaned_v4/cleaned_accounts_v4.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/cleaned_accounts_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for data in pd.read_csv(\"cleaned_v4/cleaned_accounts_v4.csv\", chunksize = 1000):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adding Missing Ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# first = pd.read_csv(\"cleaned_v4/cleaned_accounts_v4.csv\")\n",
    "second = pd.read_csv(\"cleaned_accounts_2_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chunk = pd.concat([first,second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cols = [\"keywords\",\"userdefinedfields\",\"tags\"]\n",
    "concat_cols = [\"keywords\",\"userdefinedfields\",\"tags\",\n",
    " \"preferredemail\",\"preferredcontactmethod\",\"account_name\"]\n",
    "columns = [\"account_id\",\"org_id\",\"keywords\",\"userdefinedfields\",\n",
    "           \"tags\",\"preferredemail\",\"preferredcontactmethod\",\n",
    "           \"account_name\"]\n",
    "\n",
    "if len(chunk) != len(chunk.drop_duplicates(subset = [\"account_id\",\"org_id\"])):\n",
    "    print(\"len(chunk):\",len(chunk))\n",
    "    \n",
    "    ### Simple Formatting\n",
    "    for col in concat_cols:\n",
    "        print(\"col1:\",col)\n",
    "        chunk[col] = chunk[col].apply(lambda x: x[1:-1] if type(x)==str and \"{\" in x else x)\n",
    "\n",
    "    ### Merge into Set or Dict (only keep the earliest records)\n",
    "    result = chunk.fillna(\"\").groupby([\"account_id\",\"org_id\"], \n",
    "                          as_index = False).agg({\"keywords\":\",\".join,\n",
    "                                                \"userdefinedfields\":\",\".join,\n",
    "                                                \"tags\":\",\".join,\n",
    "                                                \"preferredemail\":\",\".join,\n",
    "                                                \"preferredcontactmethod\":\",\".join,\n",
    "                                                \"account_name\":\",\".join}) \n",
    "    for col in concat_cols:\n",
    "        print(\"col2:\",col)\n",
    "        result[col] = result[col].apply(remove_duplicates2)\n",
    "    result.to_csv(f\"cleaned_v5/cleaned_accounts_v5.csv\", index = False)\n",
    "\n",
    "    print(len(result))\n",
    "else:\n",
    "    chunk.to_csv(f\"cleaned_v5/cleaned_accounts_v5.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in concat_cols:\n",
    "    print(\"col2:\",col)\n",
    "    result[col] = result[col].apply(remove_duplicates2)\n",
    "result.to_csv(f\"cleaned_v5/cleaned_accounts_v5.csv\", index = False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "with open('cleaned_v5/cleaned_accounts_v5.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/cleaned_accounts_v5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT DATA:orgid::string AS org_id,\n",
    "                    DATA:id::string as account_id,\n",
    "                    DATA:dbid::string as client_id,\n",
    "                    DATA:categories as categories,\n",
    "                    DATA:currentpoints as currentpoints,\n",
    "                    DATA:donormemberships AS donormemberships,\n",
    "                    DATA:firstallociddriveyears AS firstallociddriveyears,\n",
    "                    DATA:firstdate AS firstdate,\n",
    "                    DATA:firstgiftamount AS firstgiftamount,\n",
    "                    DATA:greatestallociddriveyears AS greatestallociddriveyears,\n",
    "                    DATA:greatestdate AS greatestdate,\n",
    "                    DATA:greatestgiftamount AS greatestgiftamount,\n",
    "                    DATA:lastallociddriveyears AS lastallociddriveyears,\n",
    "                    DATA:lastdate AS lastdate,\n",
    "                    DATA:lastgiftamount AS lastgiftamount,\n",
    "                    DATA:lastupdatemembership AS lastupdatemembership,\n",
    "                    DATA:lastupdateprioritypoints AS lastupdateprioritypoints,\n",
    "                    DATA:lastupdatestatistics AS lastupdatestatistics,\n",
    "                    DATA:lifetimedonationamount AS lifetimedonationamount,\n",
    "                    DATA:pointsrank::integer AS pointsrank,\n",
    "                    DATA:yearsofdonating::integer AS yearsofdonating\n",
    "                    from donors where lastdate>20180101\n",
    "                    limit 10''')\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "donor_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "print(donor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Donor Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cleaned donor cat\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT DATA:id::string as donor_cat_id,\n",
    "                    DATA:dbid::string as org_id,\n",
    "                    DATA:name:en_US::string as donor_cat_name\n",
    "                    from donorcategories \n",
    "                    where org_id not in ('SPORTS','ARTSDEMO','CLASS1','CLASS3A','CICD80')\n",
    "                    ''')\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "donor_cat_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "donor_cat_df=donor_cat_df.rename(columns=str.lower)\n",
    "donor_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3328rows*3cols \n",
    "donor_cat_df.to_csv(\"s3://uci-capstone-custfields/cleaned_donor_category.csv\", \n",
    "                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cleaned org\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT DATA:id::string as org_id,\n",
    "                    DATA:description:en_US::string as description,\n",
    "                    DATA:name:en_US::string AS name\n",
    "                    from organizations\n",
    "                    where org_id not in ('SPORTS','ARTSDEMO','CLASS1','CLASS3A','CICD80')\n",
    "                    ''')\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "organization_df = pd.DataFrame.from_records(iter(cur), \n",
    "                                            columns=[x[0] for x in cur.description])\n",
    "organization_df=organization_df.rename(columns=str.lower)\n",
    "organization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#293rows*3cols\n",
    "#exclude accountdbid\n",
    "organization_df.to_csv(\"s3://uci-capstone-custfields/cleaned_organizations.csv\", \n",
    "                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean allo\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT \n",
    "                    DATA:dbid::string AS org_id,\n",
    "                    DATA:allocationgroupid::string as allocationgroupid,\n",
    "                    DATA:id::string AS alloc_id,\n",
    "                    DATA:annualgift::boolean as annualgift,\n",
    "                    DATA:consumerfunddescription::string AS consumerfunddescription,\n",
    "                    DATA:charitablepercent as charitablepercent,\n",
    "                    DATA:lifetimegiving::boolean AS lifetimegiving,\n",
    "                    DATA:name:en_US::string AS name,\n",
    "                    DATA:prioritypointpercent AS prioritypointpercent,\n",
    "                    DATA:deadlineday AS deadlineday,\n",
    "                    DATA:deadlinefactor AS deadlinefactor,\n",
    "                    DATA:deadlinemonth AS deadlinemonth,\n",
    "                    DATA:deadlineyear AS deadlineyear,\n",
    "                    DATA:isexcludedfromdonationhistory AS isexcludedfromdonationhistory,\n",
    "                    DATA:yearsofgiving AS yearsofgiving\n",
    "                    from allocations\n",
    "                    where org_id not in ('SPORTS','ARTSDEMO','CLASS1','CLASS3A','CICD80')\n",
    "                    ''')\n",
    "\n",
    "\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "alloc_df = pd.DataFrame.from_records(iter(cur), \n",
    "                                            columns=[x[0] for x in cur.description])\n",
    "alloc_df=alloc_df.rename(columns=str.lower)\n",
    "alloc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10849rows*15cols\n",
    "alloc_df.to_csv(\"s3://uci-capstone-custfields/cleaned_allocations.csv\", \n",
    "                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alloc group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cleaned alloc group\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT \n",
    "                    DATA:dbid::string AS org_id,\n",
    "                    DATA:id::string AS allocationgroupid,\n",
    "                    DATA:name:en_US::string AS name\n",
    "                    from allocgroups\n",
    "                    where org_id not in ('SPORTS','ARTSDEMO','CLASS1','CLASS3A','CICD80')\n",
    "                    ''')\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "alloc_grp_df = pd.DataFrame.from_records(iter(cur), \n",
    "                                            columns=[x[0] for x in cur.description])\n",
    "alloc_grp_df=alloc_grp_df.rename(columns=str.lower)\n",
    "alloc_grp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#216rows*3col\n",
    "alloc_grp_df.to_csv(\"s3://uci-capstone-custfields/cleaned_allocations_group.csv\", \n",
    "                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transaction Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleaned trans\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT  \n",
    "                    DATA:dbid::string AS org_id,\n",
    "                    DATA:accountid::string AS account_id,\n",
    "                    DATA:allocationid::string AS allocationid,\n",
    "                    DATA:allocgroupid::string AS allocgroupid,\n",
    "                    DATA:transactionid::string AS transactionid,\n",
    "                    DATA:id::string AS transaction_item_id,\n",
    "                    DATA:batchid::string AS batchid,\n",
    "                    DATA:channelid::string AS channelid,\n",
    "                    DATA:allocationid::string AS allocationid,\n",
    "                    DATA:creditamount::string AS creditamount,\n",
    "                    DATA:driveyear AS driveyear,\n",
    "                    CONCAT(SUBSTRING(DATA:receiveddate::string,1,10),' ',SUBSTRING(DATA:receiveddate::string,12,8)) AS receiveddate,\n",
    "                    DATA:fundtype::string AS fundtype,\n",
    "                    DATA:giftid::string AS giftid,\n",
    "                    DATA:pledgeamount::string AS pledgeamount,\n",
    "                    DATA:paymentamount::string AS paymentamount,\n",
    "                    DATA:matchpledgeamount::string AS matchpledgeamount,\n",
    "                    DATA:paymentapplyamount::string AS paymentapplyamount,\n",
    "                    DATA:motiveid::string AS motiveid\n",
    "                    from transactionitems \n",
    "                    where org_id not in ('SPORTS','ARTSDEMO','CLASS1','CLASS3A','CICD80')\n",
    "                    AND SUBSTRING(receiveddate,1,4) in ('2015','2016','2017','2018','2019','2020','2021')\n",
    "                    ''')\n",
    "# WHERE LEN(DATA:keywords::STRING) > 0\n",
    "# for col1 in cur:\n",
    "# #     df = {\"account_name\":col1[0],\n",
    "# #          }\n",
    "# #     acct_list.append()\n",
    "#     print(col1)\n",
    "\n",
    "transactionItem_df = pd.DataFrame.from_records(iter(cur), \n",
    "                                            columns=[x[0] for x in cur.description])\n",
    "transactionItem_df=transactionItem_df.rename(columns=str.lower)\n",
    "transactionItem_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactionItem_df['paymentamount']= transactionItem_df['paymentamount'].astype(int)/100\n",
    "transactionItem_df['year'] = transactionItem_df['receiveddate'].apply(lambda x: x[:4])\n",
    "yearlyorgpayment = transactionItem_df[['org_id','account_id','paymentamount','year']].groupby(['org_id','account_id','year']).sum().reset_index()\n",
    "yearlyorgpayment_perperson = yearlyorgpayment.groupby(['org_id','year']).agg([\"sum\",\"mean\",\"median\",\"min\",\"max\",\"var\",\"size\"]).reset_index()\n",
    "yearlyorgpayment_perperson.columns = [\"_\".join(x) for x in yearlyorgpayment_perperson.columns.ravel()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearlyorgpayment_perperson.rename(str.lower,axis='columns',inplace=True)\n",
    "yearlyorgpayment_perperson.rename(columns={'org_id_':'org_id','year_':'year'},inplace=True)\n",
    "yearlyorgpayment_perperson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearlyorgpayment_perperson.to_csv(\"s3://uci-capstone-custfields/yearlyorgpayment_perperson.csv\", \n",
    "                             index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. DIM_DONOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data from DIM_DONOR\n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT *\n",
    "                    from dim_donor\n",
    "                    where organization_id != 'SPORTS'\n",
    "                    and organization_id != 'ARTSDEMO'\n",
    "                    and organization_id != 'CLASS1'\n",
    "                    and organization_id != 'CLASS3A'\n",
    "                    and organization_id != 'CICD80'\n",
    "                ''')\n",
    "\n",
    "donor_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "csv_buffer = StringIO()\n",
    "donor_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/dim_donors.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and reformat for future use\n",
    "donor_df = donor_df.drop(['DIM_ACCOUNT_KEY','DONOR_TYPE','DONOR_STATUS','DONOR_MEMBERSHIPS','MEMBERSHIPS'],axis=1)\n",
    "donor_df['DONOR_TYPE_NAME'] = donor_df['DONOR_TYPE_NAME'].str.strip('{\\n }')\n",
    "donor_df['DONOR_TYPE_NAME'] = donor_df['DONOR_TYPE_NAME'].str.replace('\"en_US\":','')\n",
    "donor_df['DONOR_STATUS_NAME'] = donor_df['DONOR_STATUS_NAME'].str.strip('{\\n }')\n",
    "donor_df['DONOR_STATUS_NAME'] = donor_df['DONOR_STATUS_NAME'].str.replace('\"en_US\":','')\n",
    "donor_df['CATEGORIES'] = donor_df['CATEGORIES'].str.strip('{\\n }')\n",
    "donor_df['CATEGORY_START_DATES'] = donor_df['CATEGORY_START_DATES'].str.replace(\"{}\",\"None\")\n",
    "donor_df['CATEGORY_END_DATES'] = donor_df['CATEGORY_END_DATES'].str.replace(\"{}\",\"None\")\n",
    "\n",
    "donor_df.rename(columns={'ORGANIZATION_ID':'org_id','ID':'account_id', 'IS_DELETED':'is_deleted',\n",
    "                                    'DONOR_TYPE_NAME':'donor_type','DONOR_STATUS_NAME':'donor_status',\n",
    "                                    'YEARS_OF_DONATING':'years_of_donating','CATEGORIES':'categories',\n",
    "                                    'CATEGORY_START_DATES':'cat_start_dates','CATEGORY_END_DATES':'cat_end_dates',\n",
    "                                    'SYS_STATUS':'sys_status'\n",
    "                                    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned version to s3\n",
    "csv_buffer = StringIO()\n",
    "donor_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/cleaned_dim_donors.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DIM_DONOR_MEMBERSHIP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw \n",
    "cs = omni.cursor()\n",
    "cur = cs.execute('''SELECT *\n",
    "                    from dim_donor_membership\n",
    "                    where organization_id != 'SPORTS'\n",
    "                    and organization_id != 'ARTSDEMO'\n",
    "                    and organization_id != 'CLASS1'\n",
    "                    and organization_id != 'CLASS3A'\n",
    "                    and organization_id != 'CICD80'\n",
    "                ''')\n",
    "\n",
    "donor_membership_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "csv_buffer = StringIO()\n",
    "donor_membership_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/dim_donor_membership.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_membership_df = donor_membership_df.drop(['DIM_ACCOUNT_KEY','DONOR_MEMBERSHIPS'],axis=1)\n",
    "donor_membership_df.rename(columns={'ORGANIZATION_ID':'org_id','ACCOUNT_ID':'account_id', 'MEMBERSHIP_ID':'membership_id',\n",
    "                                    'MEMBERSHIP_DRIVE_YEAR':'membership_drive_year','PLEDGED_LEVEL_NAME':'pledged_level',\n",
    "                                    'RECEIPT_LEVEL_NAME':'receipt_level','TOTAL_DONATED':'total_donated',\n",
    "                                    'TOTAL_PLEDGED':'total_pledged','DONOR_SYS_STATUS':'sys_status'}, inplace=True)\n",
    "donor_membership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned version to s3\n",
    "csv_buffer = StringIO()\n",
    "donor_membership_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/cleaned_dim_donor_membership.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_donation = donor_df[['org_id','membership_drive_year','total_donated','total_pledged']].groupby(['org_id','membership_drive_year']).agg(['sum','median','mean','var','min','max']).reset_index()\n",
    "year_donation.columns = [\"_\".join(x) if x[0] not in [\"org_id\",\"year\"] else x[0] for x in year_donation.columns.ravel()]\n",
    "yea_donation = year_donation.rename(columns={'membership_drive_year_':'year'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned version to s3\n",
    "csv_buffer = StringIO()\n",
    "year_donation.to_csv(csv_buffer,index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/cleaned_year_donation.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. AccountPriorityPointsProgramDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = omni.cursor()\n",
    "cur = cs.execute('''select DISTINCT DATA:acctid::string as account_id,\n",
    "                           DATA:actualpoints::string as actual_points,\n",
    "                           DATA:dbid::string as org_id,\n",
    "                           DATA:pointscategoriesbreakdown as points_catg,\n",
    "                           DATA:potentialpoints::int as potential_points,\n",
    "                           DATA:progid::string as prog_id,\n",
    "                           DATA:seq::int as seq\n",
    "                    from ACCOUNTPRIORITYPOINTSPROGRAMDETAILS''')\n",
    "\n",
    "priority_prog_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "# save the raw version\n",
    "csv_buffer = StringIO()\n",
    "priority_prog_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/priority_program.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_prog_df = pd.read_csv(smart_open('s3://uci-capstone-custfields/raw/priority_program.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean json format\n",
    "priority_prog_df['POINTS_CATG'] = priority_prog_df['POINTS_CATG'].str.replace('{\\n    \"actualpoints\": ','')\n",
    "priority_prog_df['POINTS_CATG'] = priority_prog_df['POINTS_CATG'].str.replace(',\\n    \"name\": {\\n      \"en_US\":',',')\n",
    "priority_prog_df['POINTS_CATG'] = priority_prog_df['POINTS_CATG'].str.replace('\\n    },\\n    \"potentialpoints\": 0\\n  },\\n  ',',')\n",
    "priority_prog_df['POINTS_CATG'] = priority_prog_df['POINTS_CATG'].str.replace('\\n    },\\n    \"potentialpoints\": 0\\n  }\\n','')\n",
    "priority_prog_df['POINTS_CATG'] = priority_prog_df['POINTS_CATG'].str.replace('\\n ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_prog_df.rename(columns={'ACCOUNT_ID':'account_id','ACTUAL_POINTS':'actual_points',\n",
    "                                'ORG_ID':'org_id','POINTS_CATG':'points_catg','POTENTIAL_POINTS':'potential_points',\n",
    "                                'PROG_ID':'prog_id','SEQ':'seq'},inplace=True)\n",
    "priority_prog_df = priority_prog_df.drop(['Unnamed: 0'],axis=1)\n",
    "priority_prog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save the cleaned version to s3\n",
    "csv_buffer = StringIO()\n",
    "priority_prog_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('uci-capstone-custfields', 'raw/cleaned_priority_program.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 10. Ticket -> events data [3 datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ticketing = sfc.connect(\n",
    "    user='cs2021_user3',\n",
    "    password='Cap2021Stone-3',\n",
    "    account='paciolan',\n",
    "    warehouse='capstone2021_wh',#'capstone2021_wh',\n",
    "    database='omni_raw',\n",
    "    schema='ticketing',\n",
    "    role = 'CAPSTONE2021_ROLE'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ticket Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cs = ticketing.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT DATA:ACTIVITY::string as ACTIVITY,\n",
    "                    DATA:SOURCE_ID::string as ORG_ID,\n",
    "                    DATA:LAST_DATETIME::datetime as LAST_DATETIME,\n",
    "                    DATA:NAME::string AS NAME,\n",
    "                    DATA:SEASON::string AS SEASON,\n",
    "                    DATA:SIZE::string AS SIZE\n",
    "                    from \"CAPSTONE2020\".\"TICKETING\".\"TK_SEASON\"''')\n",
    "\n",
    "tk_season_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "tk_season_df.columns = [c.lower() for c in tk_season_df.columns]\n",
    "print(len(tk_season_df))\n",
    "tk_season_df.to_csv(\"ticket_season.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "with open('ticket_season.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/ticket_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tk_season_df = pd.read_csv(\"ticket_season.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tk_season_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ticket Region ZIP (VMC may be vendind machine control???  VMC is unique but zip is not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cs = ticketing.cursor()\n",
    "cur = cs.execute('''SELECT DISTINCT \n",
    "                    DATA:SOURCE_ID::string as ORG_ID,\n",
    "                    DATA:VMC::string as VMC,\n",
    "                    DATA:ZIP::string AS ZIP\n",
    "                    from \"CAPSTONE2020\".\"TICKETING\".\"TK_REGION_ZIP\"''')\n",
    "\n",
    "tk_region_zip_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "tk_region_zip_df.columns = [c.lower() for c in tk_region_zip_df.columns]\n",
    "print(len(tk_region_zip_df))\n",
    "tk_region_zip_df.to_csv(\"ticket_region_zip.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "with open('ticket_region_zip.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/ticket_region_zip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tk_region_zip_df[tk_region_zip_df.org_id.str.contains(\"NCSU\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Ticket Transaction Item Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs = ticketing.cursor()\n",
    "start = time.time()\n",
    "cur = cs.execute('''SELECT DATA:CUSTOMER::string as account_id,\n",
    "                    DATA:SOURCE_ID::string as ORG_ID,\n",
    "                    DATA:TRANS_NO::string as TRANS_NO,\n",
    "                    DATA:VMC AS VMC,\n",
    "                    DATA:DATE::datetime as DATE,\n",
    "                    DATA:EVENT::string AS EVENT,\n",
    "                    DATA:SEASON::STRING AS SEASON,\n",
    "                    DATA:E_OQTY AS E_OQTY,\n",
    "                    DATA:E_PL::string AS E_PL,\n",
    "                    DATA:E_PRICE::string AS E_PRICE,\n",
    "                    DATA:TOTAL_EPAY AS TOTAL_EPAY,\n",
    "                    DATA:TOTAL_CPAY AS TOTAL_CPAY,\n",
    "                    DATA:TOTAL_FPAY AS TOTAL_FPAY,\n",
    "                    DATA:TOTAL_SPAY AS TOTAL_SPAY\n",
    "                    from \"CAPSTONE2020\".\"TICKETING\".\"TK_TRANS_ITEM_EVENT\" \n",
    "                    where YEAR(DATE) >= 2018''')\n",
    "end1 = time.time()\n",
    "print(\"execute sql:\",end1 - start)\n",
    "tk_trans_item_event_df = pd.DataFrame.from_records(iter(cur), columns=[x[0] for x in cur.description])\n",
    "end2 = time.time()\n",
    "print(\"convert to pandas df:\",end2 - end1)\n",
    "tk_trans_item_event_df.columns = [c.lower() for c in tk_trans_item_event_df.columns]\n",
    "print(len(tk_trans_item_event_df))\n",
    "tk_trans_item_event_df.to_csv(\"ticket_trans_item_event.csv\", index = False)\n",
    "end3 = time.time()\n",
    "print(\"save as csv:\",end3 - end2)\n",
    "print(tk_trans_item_event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tk_trans_item_event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "with open('ticket_trans_item_event.csv', 'rb') as data:\n",
    "    s3.upload_fileobj(data,\n",
    "                      'uci-capstone-custfields',\n",
    "                      'raw/ticket_trans_item_event.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tk_trans_item_event_df= pd.read_csv(\"ticket_trans_item_event.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_df = pd.merge(tk_trans_item_event_df,tk_season_df, on= [\"season\",\"org_id\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "merge_df[\"year\"] = merge_df.date.apply(lambda x:x[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pay = merge_df[[\"org_id\",\"account_id\",\"size\",\"year\",\"total_epay\",\"total_cpay\",\n",
    "          \"total_fpay\",\"total_spay\"]].groupby([\"org_id\",\"size\",\"year\",\n",
    "                                               \"account_id\"]).sum().reset_index()\n",
    "org_yearly_pay[\"total_pay_all\"] = org_yearly_pay.total_epay+org_yearly_pay.total_cpay+org_yearly_pay.total_fpay+org_yearly_pay.total_fpay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson = org_yearly_pay[[\"org_id\",\"size\",\"total_pay_all\",\"total_epay\",\n",
    "                                     \"year\"]].groupby([\"org_id\",\"size\",\n",
    "                                             \"year\"]).agg([\"sum\",\"mean\",\"median\",\"min\",\"max\",\n",
    "                                                           \"var\",\"size\"]).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson.columns = [\"_\".join(x) if x[0] not in [\"org_id\",\"size\",\"year\"] else x[0] for x in org_yearly_pperson.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson.to_csv(\"org_yearly_tk_pperson_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_pivot = org_yearly_pperson.pivot(index = [\"org_id\"], \n",
    "                                                    columns = [\"size\",\"year\"],\n",
    "                                                    values = [c for c in org_yearly_pperson.columns if c not in [\"org_id\",\"size\",\"year\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_pivot.total_pay_all_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pay_v2 = org_yearly_pay.pivot(index = [\"org_id\", \"account_id\",\"year\"], \n",
    "                     columns = [\"size\"],\n",
    "                     values = [\"total_pay_all\",\"total_epay\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pay_v2.columns = [\"_\".join(x) if x[0] not in [\"org_id\",\"account_id\",\"year\"] else x[0] for x in org_yearly_pay_v2.columns.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "large = [\"L\",\"H\",\"T\"]\n",
    "small = [\"S\",\"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pay_v2[\"total_pay_all_large\"] = org_yearly_pay_v2[[\"total_pay_all_T\",\"total_pay_all_L\",\n",
    "                                                              \"total_pay_all_H\"]].sum(axis = 1)\n",
    "org_yearly_pay_v2[\"total_pay_all_small\"] = org_yearly_pay_v2[[\"total_pay_all_S\",\n",
    "                                                              \"total_pay_all_M\"]].sum(axis = 1)\n",
    "org_yearly_pay_pperson_v2 = org_yearly_pay_v2[[\"org_id\",\"year\",\"total_pay_all_large\",\n",
    "                   \"total_pay_all_small\"]].groupby([\"org_id\",\"year\"]).agg([\"sum\",\"mean\",\"median\",\n",
    "                                                                           \"min\",\"max\",\n",
    "                                                           \"var\",\"size\"]).reset_index()\n",
    "org_yearly_pay_pperson_v2.columns = [\"_\".join(x) if x[0] not in [\"org_id\",\"year\"] else x[0] for x in org_yearly_pay_pperson_v2.columns.ravel()]\n",
    "org_yearly_pperson_v2_pivot = org_yearly_pay_pperson_v2.pivot(index = [\"org_id\"], \n",
    "                     columns = [\"year\"],\n",
    "                     values = [c for c in org_yearly_pay_pperson_v2.columns if c not in [\"org_id\",\"year\"]]).reset_index()\n",
    "org_yearly_pperson_v2_pivot.columns = [\"_\".join(x) if x[0] !=\"org_id\" else x[0] for x in org_yearly_pperson_v2_pivot.columns.ravel()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_v2_pivot.to_csv(\"s3://uci-capstone-custfields/org_yearly_tk_pperson_v2.csv\", \n",
    "                                 index = False)\n",
    "org_yearly_pperson_v2_pivot.to_csv(\"org_yearly_tk_pperson_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pay_pperson_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"s3://uci-capstone-custfields/org_yearly_tk_pperson_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_v2_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_v2_pivot.to_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "org_yearly_pperson_v2_pivot.to_csv(\"org_yearly_tk_pperson_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.close()\n",
    "omni.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
