{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the Organization of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org = \"USC\"\n",
    "# org = \"TAM\"\n",
    "# org = \"OKLAHOMA\"\n",
    "# org = \"BAYLOR\"\n",
    "# org = \"ECU\"\n",
    "# org = 'UT-A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Account Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Account Data For a Specific Organization, i.e. USC\n",
    "account = pd.read_csv(\"../sample_data/other_samples/acc_tags_set.csv\")\n",
    "account = account[account.org_id==org].copy()\n",
    "#account.drop(columns = [\"nan_tag\"], inplace = True)\n",
    "\n",
    "interested_tags = set()\n",
    "acc_tag_dict = defaultdict(int)\n",
    "for i in range(len(account)):\n",
    "    tag_list = ast.literal_eval(account.tags.iloc[i])\n",
    "    for t in tag_list:\n",
    "        acc_tag_dict[t]+=1\n",
    "        interested_tags.add(t)\n",
    "account_per_tag = []\n",
    "for k,v in acc_tag_dict.items():\n",
    "    account_per_tag.append({\"tag\":k,\"counts\":v })\n",
    "account_per_tag = pd.DataFrame(account_per_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Seasonal Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ticket_season = pd.read_csv(\"ticket_trans_item_event.csv\")\n",
    "# ticket_season = ticket_season[ticket_season.org_id.isin([org])].copy()\n",
    "# ticket_orgs = ticket_season.org_id.unique()\n",
    "# ticket_season.to_csv(f\"{org}_ticket_trans_item_event.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_season = pd.read_csv(f\"../sample_data/other_samples/{org}_ticket_trans_item_event.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only select the tags that have been assigned to more than 100 accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_tags = []\n",
    "error_tags = []\n",
    "# method = \"logit\"\n",
    "\n",
    "for i,tag in enumerate(interested_tags):\n",
    "    if type(tag)==str and account_per_tag[account_per_tag.tag==tag].iloc[0][\"counts\"] >100:\n",
    "        useful_tags.append(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Wide Table so that each column is a season of the organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_season_org = ticket_season[[\"account_id\",\"org_id\",\"season\",\"total_epay\",\n",
    "                                   \"e_oqty\"]].groupby([\"account_id\",\"org_id\",\n",
    "                                                       \"season\"]).sum().reset_index()\n",
    "ticket_season_org = ticket_season_org.pivot_table(index = [\"account_id\",\"org_id\"], \n",
    "                           columns = [\"season\"],\n",
    "                           values = [\"total_epay\",\"e_oqty\"]).fillna(0)\n",
    "ticket_season_org.columns = [\"_\".join(x) if x[0] not in [\"account_id\",\"org_id\"] else x[0] for x in ticket_season_org.columns.ravel()]\n",
    "temp = pd.merge(account,ticket_season_org, on = [\"account_id\",\"org_id\"], how = \"inner\")\n",
    "temp.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_season_org[ticket_season_org.e_oqty_B17>0].reset_index()[[\"account_id\",\"org_id\",\"e_oqty_B17\",\"total_epay_B17\",\n",
    "                                                                 \"e_oqty_B18\",\"total_epay_B18\",\n",
    "                                                                 \"e_oqty_B19\",\"total_epay_B19\",\n",
    "                                                                 \"e_oqty_VB17\",\"total_epay_VB17\",\n",
    "                                                                \"e_oqty_VB18\",\"total_epay_VB18\",\n",
    "                                                                 \"e_oqty_VB18\",\"total_epay_VB18\",\n",
    "                                                                 \"e_oqty_VB18\",\"total_epay_VB18\",\n",
    "                                                                 \"e_oqty_VB18\",\"total_epay_VB18\",\n",
    "                                                                 \"e_oqty_VB18\",\"total_epay_VB18\",\n",
    "                                                                \"e_oqty_VB19\",\"total_epay_VB19\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression & Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, accuracy_score)\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc(testy, pred_y, org , tag):\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = roc_auc_score(testy, pred_y)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, pred_y)\n",
    "    return lr_auc,ns_fpr, ns_tpr,lr_fpr, lr_tpr\n",
    "\n",
    "def plot_roc(ns_fpr, ns_tpr,lr_fpr, lr_tpr, tag, org):\n",
    "    \n",
    "    colors = [\"#2CBDFE\",\"#47DBCD\",\"#F3A0F2\",\"#9D2EC5\",\"#F5B14C\"]\n",
    "    # plot the roc curve for the model\n",
    "    for i,(lf, lt,color) in enumerate(zip(lr_fpr, lr_tpr, colors)):      \n",
    "        pyplot.plot(lf, lt, marker='.', label=f'CV {i+1}', color=color )\n",
    "    pyplot.plot(ns_fpr[0], ns_tpr[0], linestyle='dashdot', label='Logistic',color = \"black\")\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    \n",
    "    pyplot.title(f\"ROC Curve for Tag {tag} in {org}\")\n",
    "    # save image\n",
    "    pyplot.savefig(f'../outputs/Logistic Regression/{org}_{tag}_ROC.png',bbox_inches='tight')\n",
    "    \n",
    "    # show the plot\n",
    "    \n",
    "    pyplot.show()\n",
    "#     return lr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_season_slm(tag, org):\n",
    "    '''Get 5-fold Cross Validation Result for Logistic Regression in predicting whether the accounts\n",
    "    in a selected organization are assigned a selected tag.\n",
    "    Get the account and ticket data from previous codes to avoid copying too many data and crashing the session\n",
    "    '''\n",
    "    print(\"Selected Tag:\", tag)\n",
    "#     ----------------------------------Preprocess Data ----------------------------------\n",
    "#     Ticket Season: Number of Columns\n",
    "    print(\"old columns number:\",len(ticket_season_org.columns))\n",
    "    \n",
    "#     Account Data: Create Target Column to indicate whether and again return 0 if \n",
    "    tag_account = account.copy()\n",
    "    tag_account[\"tag\"] = tag_account.tags.str.contains(tag).fillna(False)\n",
    "    tag_num = len(tag_account[tag_account.tag])\n",
    "    if tag_num<100:\n",
    "        print(\"tag_num:\",tag_num)\n",
    "        return 0\n",
    "    \n",
    "#     Merge Account + Ticket Season    \n",
    "    temp = pd.merge(tag_account,ticket_season_org, on = [\"account_id\",\"org_id\"], how = \"left\")\n",
    "    total_number_of_account = len(temp)\n",
    "    total_number_of_acc_w_tag = len(temp[temp.tag])\n",
    "    print(\"total number of accounts labeled with tag:\", total_number_of_acc_w_tag)\n",
    "    print(\"total number of accounts: \",total_number_of_account)\n",
    "    print(\"percentage of tags:\",total_number_of_acc_w_tag/total_number_of_account)\n",
    "    \n",
    "    if len(temp[temp.tag])<100:     \n",
    "        return 0\n",
    "    \n",
    "    temp.fillna(0,inplace = True)   \n",
    "    \n",
    "#     Drop Season Columns if fewer than 1000 accounts have bought relevant tickets:\n",
    "    temp[\"intercept\"] = 1\n",
    "    temp.drop(columns = [\"tags\"], inplace = True)\n",
    "    drop_cols = []\n",
    "    for c in temp.columns:\n",
    "        if c not in [\"account_id\",\"org_id\",'tag']:\n",
    "            if len(temp[temp[c]>0])<1000:\n",
    "                drop_cols.append(c)\n",
    "    print(drop_cols)\n",
    "    temp.drop(columns = drop_cols, inplace = True)\n",
    "    \n",
    "#     The X variable Columns\n",
    "    xs = [c for c in temp.columns if c not in [\"account_id\",\"org_id\",'tag']]\n",
    "    print(\"new columns number:\",len(xs))\n",
    "\n",
    "#     Randomize the dataframe with sample and fraction = 1 and replace = False\n",
    "    np.random.seed(0)\n",
    "    temp = temp.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "#     -----------------------------------------------------------------------------------------\n",
    "# --------- Run Logistic REGRESSION on all data to get the table for p-value and coefficient---------\n",
    "#         Need to use bfgs else errors will be very frequent\n",
    "    overall_result=sm.Logit(temp.tag, temp[xs]).fit(method='bfgs')\n",
    "    print(overall_result.summary())\n",
    "    \n",
    "#    -------------------------------------------------------------------------------------------    \n",
    "#     ------------------5-FOLD Cross Validation Data Preprocess-------------------\n",
    "\n",
    "#     Split the data with tag from no tag for future 5-fold splitting\n",
    "    temp_tag = temp[temp.tag].copy()\n",
    "    temp = temp[~temp.tag]\n",
    "\n",
    "#     # Tags Train Split - index\n",
    "    arr_tags = np.arange(len(temp_tag))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(arr_tags)\n",
    "    arr_tags=np.array_split(arr_tags, 5)\n",
    "    \n",
    "#     # Not Tags Train Split - index\n",
    "    arr_no_tags = np.arange(len(temp))\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(arr_no_tags)\n",
    "    arr_no_tags=np.array_split(arr_no_tags, 5)\n",
    "    \n",
    "    temp.reset_index(inplace = True)\n",
    "    temp_tag.reset_index(inplace = True)\n",
    "\n",
    "#     ------------------5-FOLD Cross Validation and Metrics-------------------\n",
    "    \n",
    "    average_mse =0\n",
    "    avg_specificity = 0\n",
    "    avg_sensitivity = 0\n",
    "    avg_f1 = 0\n",
    "    sense_gd=True\n",
    "    spec_gd = True\n",
    "    avg_auc_score=0\n",
    "    ns_fprs, ns_tprs,lr_fprs, lr_tprs = [],[],[],[]\n",
    "    for i,(ari1, ari2) in enumerate(zip(arr_no_tags, arr_tags)):\n",
    "#         Train Test split using the previously prepared indexes in each fold\n",
    "        temp_test = pd.concat([temp.iloc[ari1],\n",
    "                             temp_tag.iloc[ari2]]).reset_index()\n",
    "        temp_tr = pd.concat([temp.drop(ari1,axis =0),\n",
    "                               temp_tag.drop(ari2,axis =0)])\n",
    "        temp_tr = temp_tr.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#       Train Logistic Regression Model \n",
    "        result=sm.Logit(temp_tr.tag, temp_tr[xs]).fit(method='bfgs')\n",
    "\n",
    "#       Prediction\n",
    "        predicted = result.predict(temp_test[xs])\n",
    "    \n",
    "#       Calculate AUC Score and Plot ROC Curve\n",
    "        auc_score, ns_fpr, ns_tpr,lr_fpr, lr_tpr = get_roc(temp_test.tag, predicted, \n",
    "                                                           org , tag)\n",
    "        ns_fprs.append(ns_fpr)\n",
    "        ns_tprs.append(ns_tpr)\n",
    "        lr_tprs.append(lr_tpr)\n",
    "        lr_fprs.append(lr_fpr)\n",
    "        \n",
    "#         plot_roc( temp_test.tag, predicted, org, tag, i)  \n",
    "        avg_auc_score+=auc_score\n",
    "#           Use 0.5 as threshold: <0.5 means no tag; >=0.5 means tag\n",
    "        predicted = np.where(predicted<0.5,0,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         Calculate Measure Metrics:\n",
    "#       mse, true_positive, false_negative,true_negative,false_positive\n",
    "        mse = np.sum((predicted - temp_test.tag)**2)/len( temp_test.tag)\n",
    "\n",
    "        average_mse+=mse\n",
    "        true_positive = 0\n",
    "        false_negative = 0\n",
    "        true_negative = 0\n",
    "        false_positive= 0\n",
    "        \n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] and temp_test.tag.iloc[i]:\n",
    "                true_positive+=1\n",
    "            elif not predicted[i] and not temp_test.tag.iloc[i]:\n",
    "                true_negative+=1\n",
    "            elif predicted[i] and not temp_test.tag.iloc[i]:\n",
    "                false_negative+=1\n",
    "            else:\n",
    "                false_positive+=1\n",
    "        print(true_positive,false_negative,true_negative,false_positive)\n",
    "        if true_positive+false_negative!=0:\n",
    "            sensitivity = true_positive/(true_positive+false_negative)\n",
    "            avg_sensitivity+=sensitivity\n",
    "#             print(i,\"sensitivity:\",sensitivity)\n",
    "        else:\n",
    "            sense_gd=False\n",
    "        if true_negative+false_positive!=0:\n",
    "            specificity = true_negative/(true_negative+false_positive) \n",
    "            avg_specificity+=specificity\n",
    "#             print(i,\"specificity:\",specificity)\n",
    "        else:\n",
    "            spec_gd = False\n",
    "            \n",
    "        avg_f1 += true_positive/(true_positive+(false_positive+false_negative)/2)\n",
    "    \n",
    "    print(\"ns_fprs:\",ns_fprs)\n",
    "#     print(\"ns_tprs:\",ns_tprs)\n",
    "#     print(\"lr_fprs:\",lr_fprs)\n",
    "#     print(\"lr_tprs:\",lr_tprs)\n",
    "    plot_roc( ns_fprs, ns_tprs, lr_fprs, lr_tprs, tag, org)    \n",
    "    if sense_gd:\n",
    "        avg_sensitivity = avg_sensitivity/5\n",
    "        print(\"avg_sensitivity:\",avg_sensitivity)\n",
    "    if spec_gd:\n",
    "        avg_specificity = avg_specificity/5\n",
    "        print(\"avg_specificity:\",avg_specificity)\n",
    "        \n",
    "    avg_f1 = avg_f1/5\n",
    "    print(\"avg_f1 score:\", avg_f1)\n",
    "              \n",
    "    average_mse = average_mse/5\n",
    "    print(\"average_mse score:\", average_mse)\n",
    "    \n",
    "    avg_auc_score = avg_auc_score/5\n",
    "    print(\"avg_auc_score score:\", avg_auc_score)\n",
    "    \n",
    "    result = {\"overall_result\":overall_result, \n",
    "              \"prsquared\": overall_result.prsquared, \n",
    "              \"total_number_of_account\":total_number_of_account,\n",
    "              \"total_number_of_acc_w_tag\":total_number_of_acc_w_tag,\n",
    "              \"Percentage of Tag\": total_number_of_acc_w_tag/total_number_of_account,\n",
    "              \"Correct Percentage\":average_mse,\n",
    "              \"avg_f1\":avg_f1,\n",
    "              \"avg_auc\": avg_auc_score,\n",
    "              \"avg_sensitivity\":avg_sensitivity,\n",
    "              \"avg_specificity\":avg_specificity,\n",
    "              \"sense_gd\":sense_gd, \n",
    "              \"spec_gd\":spec_gd}\n",
    "    return result, temp_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags_dict = dict()\n",
    "for tag in [\"fbbb\",\"fbonly\"]:\n",
    "    print(tag)\n",
    "    result, temp_test = calculate_season_slm(tag, org)\n",
    "#     break\n",
    "#     print(result)\n",
    "    if result!=0:\n",
    "        tags_dict[tag] = result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(useful_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Result (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_model_result(tags_dict, sort_by_cols=[\"avg_sensitivity\",\"avg_specificity\"]):\n",
    "    temp = []\n",
    "    for k,v in tags_dict.items():\n",
    "        tags_dict[k][\"tag\"]=k\n",
    "        temp.append(tags_dict[k])\n",
    "    tags_dict = pd.DataFrame(temp)\n",
    "    return tags_dict.sort_values(by = sort_by_cols,ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_model_result(tags_dict, [\"avg_sensitivity\",\"avg_specificity\"]).to_csv(\n",
    "    f\"../outputs/Logistic Regression/tag_prediction_result_{org}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
